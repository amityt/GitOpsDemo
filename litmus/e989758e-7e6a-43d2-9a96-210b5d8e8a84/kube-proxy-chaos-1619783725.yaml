apiVersion: argoproj.io/v1alpha1
kind: CronWorkflow
metadata:
  creationTimestamp: null
  labels:
    cluster_id: 87870497-8992-4571-b71d-f0f713ed3802
    workflow_id: d346725a-0257-4f88-8536-cafc5d8fb05f
    workflows.argoproj.io/controller-instanceid: 87870497-8992-4571-b71d-f0f713ed3802
  name: kube-proxy-chaos-1619783725
  namespace: litmus
spec:
  concurrencyPolicy: Forbid
  schedule: 26 0-23 * * *
  startingDeadlineSeconds: 0
  timezone: Asia/Calcutta
  workflowMetadata:
    creationTimestamp: null
    labels:
      cluster_id: 87870497-8992-4571-b71d-f0f713ed3802
      workflow_id: d346725a-0257-4f88-8536-cafc5d8fb05f
      workflows.argoproj.io/controller-instanceid: 87870497-8992-4571-b71d-f0f713ed3802
  workflowSpec:
    arguments:
      parameters:
      - name: adminModeNamespace
        value: litmus
    entrypoint: argowf-chaos
    securityContext:
      runAsNonRoot: true
      runAsUser: 1000
    serviceAccountName: argo-chaos
    templates:
    - arguments: {}
      inputs: {}
      metadata: {}
      name: argowf-chaos
      outputs: {}
      steps:
      - - arguments: {}
          name: install-chaos-experiments
          template: install-chaos-experiments
      - - arguments: {}
          name: node-cpu-hog
          template: node-cpu-hog
        - arguments: {}
          name: pod-memory-hog
          template: pod-memory-hog
      - - arguments: {}
          name: pod-cpu-hog
          template: pod-cpu-hog
        - arguments: {}
          name: node-memory-hog
          template: node-memory-hog
      - - arguments: {}
          name: pod-delete
          template: pod-delete
      - - arguments: {}
          name: revert-kube-proxy-chaos
          template: revert-kube-proxy-chaos
    - arguments: {}
      container:
        args:
        - kubectl apply -f https://hub.litmuschaos.io/api/chaos/1.13.3?file=charts/generic/experiments.yaml -n {{workflow.parameters.adminModeNamespace}} | sleep 30
        command:
        - sh
        - -c
        image: litmuschaos/k8s:latest
        name: ""
        resources: {}
      inputs: {}
      metadata: {}
      name: install-chaos-experiments
      outputs: {}
    - arguments: {}
      container:
        args:
        - -file=/tmp/chaosengine-node-cpu-hog.yaml
        - -saveName=/tmp/engine-name
        image: litmuschaos/litmus-checker:latest
        name: ""
        resources: {}
      inputs:
        artifacts:
        - name: node-cpu-hog
          path: /tmp/chaosengine-node-cpu-hog.yaml
          raw:
            data: |
              apiVersion: litmuschaos.io/v1alpha1
              kind: ChaosEngine
              metadata:
                name: kube-proxy-node-cpu-hog-1619783688
                namespace: "{{workflow.parameters.adminModeNamespace}}"
                labels:
                  context: litmus-kube-proxy-node-cpu-hog-1619783688
              spec:
                jobCleanUpPolicy: retain
                annotationCheck: "false"
                engineState: active
                chaosServiceAccount: litmus-admin
                experiments:
                  - name: node-cpu-hog
                    spec:
                      components:
                        env:
                          - name: NODE_CPU_CORE
                            value: "1"
                          - name: TOTAL_CHAOS_DURATION
                            value: "60"
                      probe: []
      metadata:
        labels:
          weight: "6"
      name: node-cpu-hog
      outputs: {}
    - arguments: {}
      container:
        args:
        - -file=/tmp/chaosengine-pod-memory-hog.yaml
        - -saveName=/tmp/engine-name
        image: litmuschaos/litmus-checker:latest
        name: ""
        resources: {}
      inputs:
        artifacts:
        - name: pod-memory-hog
          path: /tmp/chaosengine-pod-memory-hog.yaml
          raw:
            data: |
              apiVersion: litmuschaos.io/v1alpha1
              kind: ChaosEngine
              metadata:
                name: kube-proxy-pod-memory-hog-chaos-1619783688
                namespace: "{{workflow.parameters.adminModeNamespace}}"
              spec:
                appinfo:
                  appns: kube-system
                  applabel: k8s-app=kube-proxy
                  appkind: daemonset
                jobCleanUpPolicy: retain
                annotationCheck: "false"
                engineState: active
                chaosServiceAccount: litmus-admin
                experiments:
                  - name: pod-memory-hog
                    spec:
                      components:
                        env:
                          - name: TARGET_CONTAINER
                            value: kube-proxy
                          - name: MEMORY_CONSUMPTION
                            value: "500"
                          - name: TOTAL_CHAOS_DURATION
                            value: "60"
                          - name: CHAOS_KILL_COMMAND
                            value: kill $(find /proc -name exe -lname '*/dd' 2>&1 | grep -v 'Permission
                              denied' | awk -F/ '{print $(NF-1)}' |  head -n 1)
      metadata:
        labels:
          weight: "8"
      name: pod-memory-hog
      outputs: {}
    - arguments: {}
      container:
        args:
        - -file=/tmp/chaosengine-pod-cpu-hog.yaml
        - -saveName=/tmp/engine-name
        image: litmuschaos/litmus-checker:latest
        name: ""
        resources: {}
      inputs:
        artifacts:
        - name: pod-cpu-hog
          path: /tmp/chaosengine-pod-cpu-hog.yaml
          raw:
            data: |
              apiVersion: litmuschaos.io/v1alpha1
              kind: ChaosEngine
              metadata:
                name: kube-proxy-pod-cpu-hog-chaos-1619783688
                namespace: "{{workflow.parameters.adminModeNamespace}}"
              spec:
                appinfo:
                  appns: kube-system
                  applabel: k8s-app=kube-proxy
                  appkind: daemonset
                jobCleanUpPolicy: retain
                annotationCheck: "false"
                engineState: active
                chaosServiceAccount: litmus-admin
                experiments:
                  - name: pod-cpu-hog
                    spec:
                      components:
                        env:
                          - name: TARGET_CONTAINER
                            value: kube-proxy
                          - name: CPU_CORES
                            value: "1"
                          - name: TOTAL_CHAOS_DURATION
                            value: "60"
                          - name: CHAOS_KILL_COMMAND
                            value: kill $(find /proc -name exe -lname '*/md5sum' 2>&1 | grep -v 'Permission
                              denied' | awk -F/ '{print $(NF-1)}' |  head -n 1)
      metadata:
        labels:
          weight: "3"
      name: pod-cpu-hog
      outputs: {}
    - arguments: {}
      container:
        args:
        - -file=/tmp/chaosengine-node-memory-hog.yaml
        - -saveName=/tmp/engine-name
        image: litmuschaos/litmus-checker:latest
        name: ""
        resources: {}
      inputs:
        artifacts:
        - name: node-memory-hog
          path: /tmp/chaosengine-node-memory-hog.yaml
          raw:
            data: |
              apiVersion: litmuschaos.io/v1alpha1
              kind: ChaosEngine
              metadata:
                name: kube-proxy-node-memory-hog-chaos-1619783688
                namespace: "{{workflow.parameters.adminModeNamespace}}"
              spec:
                jobCleanUpPolicy: retain
                annotationCheck: "false"
                engineState: active
                chaosServiceAccount: litmus-admin
                experiments:
                  - name: node-memory-hog
                    spec:
                      components:
                        env:
                          - name: MEMORY_PERCENTAGE
                            value: "50"
                          - name: TOTAL_CHAOS_DURATION
                            value: "60"
      metadata:
        labels:
          weight: "5"
      name: node-memory-hog
      outputs: {}
    - arguments: {}
      container:
        args:
        - -file=/tmp/chaosengine-pod-delete.yaml
        - -saveName=/tmp/engine-name
        image: litmuschaos/litmus-checker:latest
        name: ""
        resources: {}
      inputs:
        artifacts:
        - name: pod-delete
          path: /tmp/chaosengine-pod-delete.yaml
          raw:
            data: |
              apiVersion: litmuschaos.io/v1alpha1
              kind: ChaosEngine
              metadata:
                name: kube-proxy-pod-delete-chaos-1619783688
                namespace: "{{workflow.parameters.adminModeNamespace}}"
              spec:
                appinfo:
                  appns: kube-system
                  applabel: k8s-app=kube-proxy
                  appkind: daemonset
                jobCleanUpPolicy: retain
                annotationCheck: "false"
                engineState: active
                chaosServiceAccount: litmus-admin
                experiments:
                  - name: pod-delete
                    spec:
                      components:
                        env:
                          - name: TOTAL_CHAOS_DURATION
                            value: "60"
                          - name: CHAOS_INTERVAL
                            value: "10"
                          - name: FORCE
                            value: "false"
      metadata:
        labels:
          weight: "10"
      name: pod-delete
      outputs: {}
    - arguments: {}
      container:
        args:
        - kubectl delete chaosengine kube-proxy-node-cpu-hog-1619783688 kube-proxy-pod-memory-hog-chaos-1619783688 kube-proxy-pod-cpu-hog-chaos-1619783688 kube-proxy-node-memory-hog-chaos-1619783688 kube-proxy-pod-delete-chaos-1619783688  -n {{workflow.parameters.adminModeNamespace}}
        command:
        - sh
        - -c
        image: litmuschaos/k8s:latest
        name: ""
        resources: {}
      inputs: {}
      metadata: {}
      name: revert-kube-proxy-chaos
      outputs: {}
status: {}
